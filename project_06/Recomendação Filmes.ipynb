{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistema de Recomendação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constantes usadas no processamento das legendas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TITLE = re.compile(\"(\\/)(.*?)(\\.)\")\n",
    "HTML_TAG = re.compile(\"<.*?>\")\n",
    "\n",
    "STOP_WORDS = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000 B.C.(2008).XViD-PreVaill.br.srt</td>\n",
       "      <td>Ação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127 Hours (2010).BDRip.Larceny.br.srt</td>\n",
       "      <td>Aventura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12 Rounds.DVDRip.aXXo.br.srt</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Minutes(2001).br.srt</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17 Again.720p.REFiNED.br.srt</td>\n",
       "      <td>Comédia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filepath     genre\n",
       "0  10000 B.C.(2008).XViD-PreVaill.br.srt      Ação\n",
       "1  127 Hours (2010).BDRip.Larceny.br.srt  Aventura\n",
       "2           12 Rounds.DVDRip.aXXo.br.srt     Crime\n",
       "3                15 Minutes(2001).br.srt     Crime\n",
       "4           17 Again.720p.REFiNED.br.srt   Comédia"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs = pd.read_csv(\"./categories.tsv\", sep=\"\\t\", names=[\"filepath\", \"genre\"])\n",
    "subs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def canonize(text):\n",
    "    text = HTML_TAG.sub(\"\", text)\n",
    "    return text\n",
    "\n",
    "def parse_text(filepath):\n",
    "    def parse_block(block):\n",
    "        lines   = block.split('\\n')\n",
    "        txt     = ' '.join(lines[2:])\n",
    "        txt     = canonize(txt)\n",
    "        return txt\n",
    "    \n",
    "    # We don't consider the first and last three blocks, since usually they're credits for\n",
    "    # the translators and/or style definition for the subtitles.\n",
    "    with open(filepath, encoding=\"latin-1\") as f:\n",
    "        sub_file = f.read()\n",
    "        sub_file = sub_file.strip().replace('\\r', '').split('\\n\\n')[3:-3]\n",
    "        lines = map(parse_block, sub_file)\n",
    "        return ' '.join(lines).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>genre</th>\n",
       "      <th>subtitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000 B.C.(2008).XViD-PreVaill.br.srt</td>\n",
       "      <td>Ação</td>\n",
       "      <td>E será sussurrada aos quatro ventos das grande...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127 Hours (2010).BDRip.Larceny.br.srt</td>\n",
       "      <td>Aventura</td>\n",
       "      <td>mas pense no que vamos tocar. Por favor. Preci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12 Rounds.DVDRip.aXXo.br.srt</td>\n",
       "      <td>Crime</td>\n",
       "      <td>Revisão: Bozano, Nininha e Virtualnet.  00:00:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Minutes(2001).br.srt</td>\n",
       "      <td>Crime</td>\n",
       "      <td>-Não perca tempo. -Está bem Ouviu o que eu dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17 Again.720p.REFiNED.br.srt</td>\n",
       "      <td>Comédia</td>\n",
       "      <td>O'Donnell, poupe-se para o jogo! Só estou aque...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filepath     genre  \\\n",
       "0  10000 B.C.(2008).XViD-PreVaill.br.srt      Ação   \n",
       "1  127 Hours (2010).BDRip.Larceny.br.srt  Aventura   \n",
       "2           12 Rounds.DVDRip.aXXo.br.srt     Crime   \n",
       "3                15 Minutes(2001).br.srt     Crime   \n",
       "4           17 Again.720p.REFiNED.br.srt   Comédia   \n",
       "\n",
       "                                            subtitle  \n",
       "0  E será sussurrada aos quatro ventos das grande...  \n",
       "1  mas pense no que vamos tocar. Por favor. Preci...  \n",
       "2  Revisão: Bozano, Nininha e Virtualnet.  00:00:...  \n",
       "3  -Não perca tempo. -Está bem Ouviu o que eu dis...  \n",
       "4  O'Donnell, poupe-se para o jogo! Só estou aque...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtitle = []\n",
    "\n",
    "for row in subs['filepath']:\n",
    "    filepath = 'Legendas/' + row\n",
    "    try:\n",
    "        text = parse_text(filepath)\n",
    "    except FileNotFoundError:\n",
    "        text = None\n",
    "\n",
    "    subtitle.append(text)\n",
    "\n",
    "# add subtitle column to our subs df\n",
    "subs['subtitle'] = subtitle\n",
    "\n",
    "# remove rows with NAs\n",
    "subs = subs.dropna()\n",
    "\n",
    "subs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos em mãos todos os dados que iremos precisarpara realizar as nossas análises e treinar nossos modelos de predição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def tokenize(text, stem=False):\n",
    "    ''' Tokenizer\n",
    "    \n",
    "    receives text (string) and return list of tokenized text, can receive an extra parameter in order\n",
    "    to stem the strings.\n",
    "    '''\n",
    "    sent_tokenizer = nltk.data.load('tokenizers/punkt/portuguese.pickle')\n",
    "    \n",
    "    tokens = [word.lower() for sentence in sent_tokenizer.tokenize(text) \\\n",
    "              for word in nltk.word_tokenize(sentence) if word.isalpha()]\n",
    "    if stem:\n",
    "        stemmer = nltk.stem.RSLPStemmer()\n",
    "        stems = [stemmer.stem(token) for token in tokens]\n",
    "        return stems\n",
    "    else:\n",
    "        return tokens\n",
    "    \n",
    "def tokenize_and_stem(text):\n",
    "    return tokenize(text, stem=True)\n",
    "\n",
    "# define TF-IDF parameters (w/o stemming)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                   min_df=0.2, stop_words=STOP_WORDS,\n",
    "                                  use_idf=True, tokenizer=tokenize, ngram_range=(1,3))\n",
    "\n",
    "# define TF-IDF parameters (w/ stemming)\n",
    "tfidf_vectorizer_stemmed = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                   min_df=0.2, stop_words=STOP_WORDS,\n",
    "                                  use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo as matrizes dos termos e documentos usando o algoritmo _TF-IDF_, podemos então treinar nos classificadores utilizando a matriz com os termos com e sem _stemming_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 44s, sys: 2.76 s, total: 2min 46s\n",
      "Wall time: 2min 52s\n",
      "shape of TF-IDF Matrix:  (644, 1648)\n",
      "\n",
      "CPU times: user 6min 13s, sys: 3.23 s, total: 6min 16s\n",
      "Wall time: 6min 26s\n",
      "shape of TF-IDF Matrix (stemmed tokens):  (644, 2027)\n"
     ]
    }
   ],
   "source": [
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(subs['subtitle'])\n",
    "print(\"shape of TF-IDF Matrix: \", tfidf_matrix.shape)\n",
    "\n",
    "# adding a blank line in-between\n",
    "print()\n",
    "\n",
    "%time tfidf_matrix_stemmed = tfidf_vectorizer_stemmed.fit_transform(subs['subtitle'])\n",
    "print(\"shape of TF-IDF Matrix (stemmed tokens): \", tfidf_matrix_stemmed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lembrar que indice retorna sempre a si mesmo, com uma distancia zero, ja que usamo o mesmos dados para treinar e para verificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=12).fit(tfidf_matrix)\n",
    "distantes, indices = nbrs.kneighbors(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 506, 362, ..., 266, 170,  72],\n",
       "       [  1, 536, 124, ..., 131, 266, 151],\n",
       "       [  2, 362, 131, ..., 576, 360, 506],\n",
       "       ..., \n",
       "       [641, 161, 266, ..., 536, 361, 124],\n",
       "       [642, 360, 151, ..., 576, 361, 124],\n",
       "       [643, 170, 350, ..., 266, 536, 361]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_choose(matrix, n):\n",
    "    num_rows = tfidf_matrix.shape[0]\n",
    "    random_row_ids = np.random.choice(num_rows, n, replace=False)\n",
    "    \n",
    "    return random_row_ids\n",
    "\n",
    "def get_top_recomendations(choosed, matrix, k):\n",
    "    # Get the mean of all the choosed vectors     \n",
    "    avg_vector = sum([matrix.getrow(idx) for idx in choosed]) / len(choosed)\n",
    "    \n",
    "    cos_similarities = linear_kernel(avg_vector, matrix)[0]\n",
    "    # get the nearest neighbors to the new avg_vector\n",
    "    recommended = cos_similarities.argsort()[:-(50+k):-1]\n",
    "    # we usually get entries from the choosed vector, since we're\n",
    "    # using the same dataset to test and to search for recommendations.\n",
    "    recommended = [(cos_similarities[i], i) for i in recommended if i not in choosed]\n",
    "    \n",
    "    return recommended[:k]\n",
    "\n",
    "def make_experiment_row(k, n, choosed, recommended):\n",
    "    avg_similarity = sum(elem[0] for elem in recommended) / len(recommended)\n",
    "    recommended = [elem[1] for elem in recommended]\n",
    "    \n",
    "    return {'N':n,\n",
    "            'K': k,\n",
    "            'Choosed':choosed,\n",
    "            'Recommended':recommended,\n",
    "            'Avg. Similarity':avg_similarity,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_experiment(matrix, Ns, Ks):\n",
    "    # Number of experiments is equal to len(Ns) * len(Ks)\n",
    "    index = np.arange(len(Ns) * len(Ks))\n",
    "    results = []\n",
    "    for n in Ns:\n",
    "        choosed = random_choose(matrix, n)\n",
    "        for k in Ks:\n",
    "            # Columns\n",
    "            recomendations = get_top_recomendations(choosed, matrix, k)\n",
    "            # Make new row and append to results\n",
    "            result_row = make_experiment_row(k, n, choosed, recomendations)\n",
    "            results.append(result_row)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>K</th>\n",
       "      <th>Choosed</th>\n",
       "      <th>Recommended</th>\n",
       "      <th>Avg. Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>[629, 561]</td>\n",
       "      <td>[375, 308, 552, 224, 291]</td>\n",
       "      <td>0.368934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>[629, 561]</td>\n",
       "      <td>[375, 308, 552, 224, 291, 567, 377, 37, 367, 215]</td>\n",
       "      <td>0.362115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>[629, 561]</td>\n",
       "      <td>[375, 308, 552, 224, 291, 567, 377, 37, 367, 2...</td>\n",
       "      <td>0.355925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[567, 350, 617, 136]</td>\n",
       "      <td>[85, 405, 423, 492, 430]</td>\n",
       "      <td>0.291633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>[567, 350, 617, 136]</td>\n",
       "      <td>[85, 405, 423, 492, 430, 544, 340, 603, 377, 193]</td>\n",
       "      <td>0.285011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>[567, 350, 617, 136]</td>\n",
       "      <td>[85, 405, 423, 492, 430, 544, 340, 603, 377, 1...</td>\n",
       "      <td>0.280221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>[188, 364, 412, 101, 486, 599, 140, 329]</td>\n",
       "      <td>[164, 622, 377, 234, 55]</td>\n",
       "      <td>0.364421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>[188, 364, 412, 101, 486, 599, 140, 329]</td>\n",
       "      <td>[164, 622, 377, 234, 55, 245, 176, 500, 340, 451]</td>\n",
       "      <td>0.358920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>[188, 364, 412, 101, 486, 599, 140, 329]</td>\n",
       "      <td>[164, 622, 377, 234, 55, 245, 176, 500, 340, 4...</td>\n",
       "      <td>0.355476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>[472, 520, 278, 388, 545, 402, 156, 39, 221, 5...</td>\n",
       "      <td>[167, 234, 164, 622, 594]</td>\n",
       "      <td>0.339588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>[472, 520, 278, 388, 545, 402, 156, 39, 221, 5...</td>\n",
       "      <td>[167, 234, 164, 622, 594, 512, 322, 418, 372, 74]</td>\n",
       "      <td>0.336014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>[472, 520, 278, 388, 545, 402, 156, 39, 221, 5...</td>\n",
       "      <td>[167, 234, 164, 622, 594, 512, 322, 418, 372, ...</td>\n",
       "      <td>0.333648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>[559, 435, 467, 573, 530, 423, 80, 618, 383, 9...</td>\n",
       "      <td>[234, 377, 320, 636, 372]</td>\n",
       "      <td>0.306753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>[559, 435, 467, 573, 530, 423, 80, 618, 383, 9...</td>\n",
       "      <td>[234, 377, 320, 636, 372, 340, 164, 510, 176, ...</td>\n",
       "      <td>0.301872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>[559, 435, 467, 573, 530, 423, 80, 618, 383, 9...</td>\n",
       "      <td>[234, 377, 320, 636, 372, 340, 164, 510, 176, ...</td>\n",
       "      <td>0.298261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>[471, 123, 281, 349, 573, 124, 336, 350, 587, ...</td>\n",
       "      <td>[234, 164, 622, 377, 581]</td>\n",
       "      <td>0.321666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>[471, 123, 281, 349, 573, 124, 336, 350, 587, ...</td>\n",
       "      <td>[234, 164, 622, 377, 581, 372, 167, 636, 418, ...</td>\n",
       "      <td>0.316480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>[471, 123, 281, 349, 573, 124, 336, 350, 587, ...</td>\n",
       "      <td>[234, 164, 622, 377, 581, 372, 167, 636, 418, ...</td>\n",
       "      <td>0.313118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     N   K                                            Choosed  \\\n",
       "0    2   5                                         [629, 561]   \n",
       "1    2  10                                         [629, 561]   \n",
       "2    2  15                                         [629, 561]   \n",
       "3    4   5                               [567, 350, 617, 136]   \n",
       "4    4  10                               [567, 350, 617, 136]   \n",
       "5    4  15                               [567, 350, 617, 136]   \n",
       "6    8   5           [188, 364, 412, 101, 486, 599, 140, 329]   \n",
       "7    8  10           [188, 364, 412, 101, 486, 599, 140, 329]   \n",
       "8    8  15           [188, 364, 412, 101, 486, 599, 140, 329]   \n",
       "9   16   5  [472, 520, 278, 388, 545, 402, 156, 39, 221, 5...   \n",
       "10  16  10  [472, 520, 278, 388, 545, 402, 156, 39, 221, 5...   \n",
       "11  16  15  [472, 520, 278, 388, 545, 402, 156, 39, 221, 5...   \n",
       "12  32   5  [559, 435, 467, 573, 530, 423, 80, 618, 383, 9...   \n",
       "13  32  10  [559, 435, 467, 573, 530, 423, 80, 618, 383, 9...   \n",
       "14  32  15  [559, 435, 467, 573, 530, 423, 80, 618, 383, 9...   \n",
       "15  64   5  [471, 123, 281, 349, 573, 124, 336, 350, 587, ...   \n",
       "16  64  10  [471, 123, 281, 349, 573, 124, 336, 350, 587, ...   \n",
       "17  64  15  [471, 123, 281, 349, 573, 124, 336, 350, 587, ...   \n",
       "\n",
       "                                          Recommended  Avg. Similarity  \n",
       "0                           [375, 308, 552, 224, 291]         0.368934  \n",
       "1   [375, 308, 552, 224, 291, 567, 377, 37, 367, 215]         0.362115  \n",
       "2   [375, 308, 552, 224, 291, 567, 377, 37, 367, 2...         0.355925  \n",
       "3                            [85, 405, 423, 492, 430]         0.291633  \n",
       "4   [85, 405, 423, 492, 430, 544, 340, 603, 377, 193]         0.285011  \n",
       "5   [85, 405, 423, 492, 430, 544, 340, 603, 377, 1...         0.280221  \n",
       "6                            [164, 622, 377, 234, 55]         0.364421  \n",
       "7   [164, 622, 377, 234, 55, 245, 176, 500, 340, 451]         0.358920  \n",
       "8   [164, 622, 377, 234, 55, 245, 176, 500, 340, 4...         0.355476  \n",
       "9                           [167, 234, 164, 622, 594]         0.339588  \n",
       "10  [167, 234, 164, 622, 594, 512, 322, 418, 372, 74]         0.336014  \n",
       "11  [167, 234, 164, 622, 594, 512, 322, 418, 372, ...         0.333648  \n",
       "12                          [234, 377, 320, 636, 372]         0.306753  \n",
       "13  [234, 377, 320, 636, 372, 340, 164, 510, 176, ...         0.301872  \n",
       "14  [234, 377, 320, 636, 372, 340, 164, 510, 176, ...         0.298261  \n",
       "15                          [234, 164, 622, 377, 581]         0.321666  \n",
       "16  [234, 164, 622, 377, 581, 372, 167, 636, 418, ...         0.316480  \n",
       "17  [234, 164, 622, 377, 581, 372, 167, 636, 418, ...         0.313118  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ns = [2, 4, 8, 16, 32, 64]\n",
    "Ks = [5,10, 15]\n",
    "\n",
    "results = run_experiment(tfidf_matrix, Ns, Ks)\n",
    "\n",
    "df = pd.DataFrame(results, columns=['N', 'K', 'Choosed', 'Recommended', 'Avg. Similarity'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise\n",
    "\n",
    "Para a nossa análise, consideramos N = {2, 4, 8, 16, 32, 64} e K = {5, 10, 15}, tambem vale salientar que a escolha de filmes que o usuario supostamente já assistiu e gostou foi feita de forma randomica, e o mesmo conjunto utilizado para os três possiveis tamanhos para K.\n",
    "\n",
    "Para avaliar a semelhança calculei a média da similaridade dos cossenos, dos resultados sugestionados, portanto quando maior o valor mais similar os filmes são entre si.\n",
    "\n",
    "Não consegui encontrar diferença significativa entre os resultados encontrados, portanto para uma escolhe de forma aleatoria, a qualidade dos resultados é estatisticamente o mesmo.\n",
    "\n",
    "Uma futura análise, com dados de gosto real de um usuario pode levar a diferentes conclusões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
